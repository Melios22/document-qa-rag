# Vietnamese RAG System - Complete Project Guide

## ğŸ¯ High-Level Overview

This is a **complete Vietnamese Retrieval-Augmented Generation (RAG) system** that processes PDF documents, builds a hybrid vector database, and provides intelligent question-answering capabilities using advanced language models.

### ğŸ”§ **System Architecture**

```
ğŸ“„ PDF Documents â†’ ğŸ”„ Preprocessing â†’ ğŸ—ƒï¸ Vector Database â†’ ğŸ¤– RAG Query System
```

**Key Components:**
- **Document Processing**: PDF extraction and text cleaning
- **Hybrid Search**: BGE-M3 dense+sparse embeddings with Milvus vector database  
- **Unified RAG Class**: Single class with internal modularity for complete RAG flow
- **Multi-LLM Support**: Google Gemini and IBM Watsonx integration
- **Vietnamese Language**: Optimized for Vietnamese text processing

---

## ğŸ“‚ **Project Structure**

```
vietnamese-rag-system/
â”‚
â”œâ”€â”€ ğŸš€ **MAIN APPLICATIONS**
â”‚   â”œâ”€â”€ main_preprocess.py      # Step 1: Process PDF documents
â”‚   â”œâ”€â”€ main_build_rag.py       # Step 2: Build vector database  
â”‚   â”œâ”€â”€ main_search_rag.py      # Step 3: Interactive RAG queries
â”‚   â”œâ”€â”€ streamlit_app.py        # Web UI interface
â”‚   â””â”€â”€ simple_api.py           # REST API interface
â”‚
â”œâ”€â”€ ğŸ§  **CORE RAG SYSTEM** (src/)
â”‚   â”œâ”€â”€ preprocess/             # Document preprocessing
â”‚   â”‚   â”œâ”€â”€ process_pdf.py      # PDF extraction
â”‚   â”‚   â”œâ”€â”€ cleaner.py          # Text cleaning
â”‚   â”‚   â”œâ”€â”€ metadata_gen.py     # Metadata generation
â”‚   â”‚   â””â”€â”€ storage.py          # Document storage
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_builder/            # Vector database building
â”‚   â”‚   â”œâ”€â”€ builder.py          # Main RAG builder
â”‚   â”‚   â”œâ”€â”€ connection_manager.py # Database connections
â”‚   â”‚   â”œâ”€â”€ milvus.py           # Milvus operations
â”‚   â”‚   â”œâ”€â”€ model_loader.py     # Model loading
â”‚   â”‚   â””â”€â”€ vector_bge_m3.py    # BGE-M3 embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_retriever/          # **UNIFIED RAG SYSTEM** â­
â”‚   â”‚   â”œâ”€â”€ vietnamese_rag.py   # **MAIN UNIFIED CLASS**
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py    # Hybrid search logic
â”‚   â”‚   â”œâ”€â”€ llm_caller.py       # LLM integration
â”‚   â”‚   â”œâ”€â”€ model_loader.py     # Model utilities
â”‚   â”‚   â””â”€â”€ models/             # LLM implementations
â”‚   â”‚       â”œâ”€â”€ base_llm.py     # Base LLM interface
â”‚   â”‚       â”œâ”€â”€ factory.py      # Model factory
â”‚   â”‚       â”œâ”€â”€ gemini_llm.py   # Google Gemini
â”‚   â”‚       â””â”€â”€ watsonx_llm.py  # IBM Watsonx
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logging.py          # Centralized logging
â”‚   â”‚
â”‚   â”œâ”€â”€ config.json             # System configuration
â”‚   â””â”€â”€ constant.py             # System constants
â”‚
â”œâ”€â”€ ğŸ“Š **DATA & STORAGE**
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ pdf/                # Input PDF documents
â”‚   â”‚   â”œâ”€â”€ processed/          # Processed documents
â”‚   â”‚   â”œâ”€â”€ milvus.db           # Vector database
â”‚   â”‚   â””â”€â”€ vietnamese-stopwords.txt
â”‚   â””â”€â”€ logs/                   # System logs
â”‚
â”œâ”€â”€ ğŸ““ **EXAMPLES & DOCS**
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â””â”€â”€ example.ipynb       # Usage examples
â”‚   â”œâ”€â”€ ESSENTIAL_STRUCTURE.md  # This guide
â”‚   â””â”€â”€ requirements.txt        # Dependencies
â”‚
â””â”€â”€ ğŸ”§ **CONFIG & DEPLOYMENT**
    â”œâ”€â”€ .env                    # Environment variables
    â”œâ”€â”€ docker-compose.yml      # Container deployment
    â””â”€â”€ .gitignore             # Git configuration
```

---

## ğŸš€ **How to Use the System**

### **Prerequisites**
```bash
# 1. Install Python 3.8+
# 2. Install dependencies
pip install -r requirements.txt

# 3. Set up environment variables (create .env file)
GOOGLE_API_KEY=your_gemini_api_key
WATSONX_URL=your_watsonx_url
WATSONX_API_KEY=your_watsonx_key
WATSONX_PROJECT_ID=your_project_id
```

### **Step-by-Step Usage**

#### **Step 1: Process Documents** ğŸ“„â¡ï¸ğŸ”„
```bash
python main_preprocess.py
```
**What it does:**
- Reads PDF files from `data/pdf/`
- Extracts and cleans text content
- Generates metadata for each document
- Saves processed documents to `data/processed/`

#### **Step 2: Build Vector Database** ğŸ”„â¡ï¸ğŸ—ƒï¸
```bash
python main_build_rag.py
```
**What it does:**
- Loads processed documents
- Creates BGE-M3 embeddings (dense + sparse)
- Builds Milvus vector database
- Optimizes for hybrid search

#### **Step 3: Query the System** ğŸ—ƒï¸â¡ï¸ğŸ¤–
```bash
python main_search_rag.py
```
**What it does:**
- Loads the complete RAG system
- Provides interactive command-line interface
- Performs hybrid search + LLM answer generation
- Logs all Q&A interactions

#### **Alternative Interfaces**

**Web UI (Streamlit):**
```bash
streamlit run streamlit_app.py
```

**REST API:**
```bash
python simple_api.py
```

---

## ğŸ§  **Core RAG System - Unified Architecture**

### **Main Class: `VietnameseRAG`** â­

```python
from src.rag_retriever import VietnameseRAG

# Initialize the unified system
rag = VietnameseRAG(
    model_type="gemini",  # or "watsonx"
    k=10,                 # initial retrieval count
    rerank_top_k=5,       # final reranked results
)

# Complete RAG flow - One method does everything!
result = rag.answer("What is machine learning?")
print(result['answer'])

# Or just search documents
docs = rag.search("machine learning")

# Switch models easily
rag.switch_model("watsonx")

# Check system status
print(rag.status)
```

### **Internal Architecture (Modular Subclasses)**

The `VietnameseRAG` class uses **internal subclasses** for clean modularity:

```python
class VietnameseRAG:
    class DocumentRetriever:    # Internal: handles search & reranking
    class AnswerGenerator:      # Internal: handles LLM generation
    
    # Main API methods:
    def answer(query):         # Complete RAG flow
    def search(query):         # Document search only  
    def switch_model(type):    # Change LLM model
    def status():              # System information
```

**Benefits:**
- âœ… **Single file** with complete functionality
- âœ… **Internal modularity** via subclasses
- âœ… **Clean API** - main `answer()` method
- âœ… **Easy model switching**
- âœ… **Backward compatibility**

---

## ğŸ”§ **Technical Deep Dive**

### **Hybrid Search System**
- **BGE-M3 Model**: Dense + sparse embeddings in one model
- **Milvus Database**: High-performance vector storage
- **RRF Fusion**: Combines dense and sparse search results
- **Reranking**: Final relevance scoring for top results

### **LLM Integration**
- **Factory Pattern**: Easy addition of new models
- **Multiple Models**: Google Gemini, IBM Watsonx
- **Unified Interface**: Same API for all models
- **Error Handling**: Graceful fallbacks and logging

### **Vietnamese Language Support**
- **Stopwords**: Vietnamese-specific text filtering
- **BGE-M3**: Multilingual model with Vietnamese support
- **Text Cleaning**: Vietnamese text preprocessing
- **Encoding**: Proper UTF-8 handling throughout

### **Logging System**
- **File-based**: Separate logs for each component
- **Milestone Tracking**: Important events highlighted
- **Q&A History**: Complete interaction logging
- **Error Management**: Comprehensive error tracking

---

## ğŸ“‹ **Configuration**

### **Main Configuration (`src/config.json`)**
```json
{
  "models": {
    "embedding": "BAAI/bge-m3",
    "reranker": "BAAI/bge-reranker-v2-m3"
  },
  "retrieval": {
    "k": 10,
    "rerank_top_k": 5,
    "similarity_threshold": 0.3
  },
  "llm": {
    "default_model": "gemini",
    "temperature": 0.1
  }
}
```

### **Environment Variables (`.env`)**
```bash
# Google Gemini
GOOGLE_API_KEY=your_gemini_api_key

# IBM Watsonx
WATSONX_URL=your_watsonx_url
WATSONX_API_KEY=your_watsonx_key
WATSONX_PROJECT_ID=your_project_id

# Optional: Database settings
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

---

## ğŸ§ª **Testing & Development**

### **Quick Test**
```bash
python test_essentials.py
```

### **Development Workflow**
1. **Add documents**: Place PDFs in `data/pdf/`
2. **Preprocess**: Run `main_preprocess.py`
3. **Build**: Run `main_build_rag.py`  
4. **Test**: Run `main_search_rag.py`
5. **Deploy**: Use `streamlit_app.py` or `simple_api.py`

### **Adding New LLM Models**
1. Create new model class in `src/rag_retriever/models/`
2. Inherit from `BaseLLM`
3. Add to factory in `factory.py`
4. Use with `rag.switch_model("your_model")`

---

## ğŸ³ **Deployment**

### **Docker Deployment**
```bash
docker-compose up -d
```

### **Production Considerations**
- **GPU Support**: For faster embedding generation
- **API Rate Limits**: Monitor LLM API usage
- **Vector Database**: Consider Milvus cluster for scale
- **Caching**: Implement query result caching
- **Security**: Secure API endpoints and environment variables

---

## ğŸ“ˆ **Performance & Scaling**

### **Current Capabilities**
- **Document Capacity**: 1000+ documents tested
- **Query Speed**: ~2-5 seconds per query
- **Accuracy**: High relevance with BGE-M3 + reranking
- **Languages**: Vietnamese + multilingual support

### **Optimization Tips**
- **Batch Processing**: Process documents in batches
- **GPU Acceleration**: Use CUDA for model inference
- **Index Tuning**: Optimize Milvus index parameters
- **Model Caching**: Cache loaded models in memory

---

## ğŸ†˜ **Troubleshooting**

### **Common Issues**

**"No module named 'langchain'"**
```bash
pip install -r requirements.txt
```

**"No documents found"**
- Check `data/pdf/` folder has PDF files
- Run `main_preprocess.py` first

**"Vector database not found"**
- Run `main_build_rag.py` after preprocessing

**"LLM API errors"**
- Check your API keys in `.env` file
- Verify internet connection
- Check API quota/rate limits

### **Log Files**
- `logs/preprocess.log` - Document processing
- `logs/builder.log` - Vector database building
- `logs/retriever.log` - RAG query operations
- `logs/errors.log` - All errors
- `logs/qa_history.log` - Question-answer history

---

## ğŸ‰ **Summary**

This Vietnamese RAG system provides:

âœ… **Complete End-to-End Pipeline** from PDF to intelligent answers  
âœ… **Unified Architecture** with single main class and internal modularity  
âœ… **Multiple LLM Support** (Gemini, Watsonx) with easy switching  
âœ… **Hybrid Search** using state-of-the-art BGE-M3 embeddings  
âœ… **Vietnamese Language Optimization** throughout the pipeline  
âœ… **Production Ready** with logging, error handling, and deployment options  
âœ… **Developer Friendly** with clean APIs and comprehensive documentation  

**Perfect for:** Vietnamese document Q&A systems, knowledge bases, research assistants, and educational applications.

---

*Need help? Check the logs, review the configuration, or examine the example notebook for detailed usage patterns.*
